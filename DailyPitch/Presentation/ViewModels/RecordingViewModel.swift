import Foundation
import Combine
import SwiftUI

/// ìŒì ˆë³„ ì˜¤ë””ì˜¤ ë…¹ìŒ ë° ë¶„ì„ í™”ë©´ì˜ ViewModel
/// "ì•ˆë…•í•˜ì„¸ìš”" â†’ ["ì•ˆ": F4, "ë…•": G4, "í•˜": A4, "ì„¸": B4, "ìš”": C5] í˜•íƒœë¡œ ë¶„ì„
@MainActor
class RecordingViewModel: ObservableObject {
    
    // MARK: - Published Properties
    
    /// ë…¹ìŒ ìƒíƒœ
    @Published var isRecording = false
    @Published var recordingDuration: TimeInterval = 0
    @Published var permissionStatus: AudioPermissionStatus = .notDetermined
    @Published var errorMessage: String?
    @Published var infoMessage: String?
    @Published var currentAudioSession: AudioSession?
    @Published var showingPermissionAlert = false
    
    /// ìŒì ˆë³„ ë¶„ì„ ê²°ê³¼
    @Published var isAnalyzing = false
    @Published var analysisResult: TimeBasedAnalysisResult?
    @Published var syllableSegments: [SyllableSegment] = []
    @Published var analysisProgress: Double = 0.0
    @Published var selectedSyllableIndex: Int?
    
    /// ê°œë³„ ìŒì ˆ ì¬ìƒ
    @Published var playingSyllableIndex: Int?
    @Published var synthesizedAudios: [Int: SynthesizedAudio] = [:]
    @Published var isGeneratingAudio = false
    
    /// ì „ì²´ ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì¶œí•œ ëŒ€í‘œ ìŒê³„ ì •ë³´ (ContentView UIì—ì„œ ì‚¬ìš©)
    @Published var detectedNote: String?
    @Published var peakFrequency: Double?
    @Published var frequencyAccuracy: Double?
    
    // MARK: - Private Properties
    
    private let recordAudioUseCase: RecordAudioUseCase
    private let syllableAnalysisUseCase: SyllableAnalysisUseCase
    private let synthesizeAudioUseCase: SynthesizeAudioUseCase
    private let audioPlaybackUseCase: AudioPlaybackUseCase
    private var cancellables = Set<AnyCancellable>()
    
    // MARK: - Computed Properties
    
    var recordingTimeString: String {
        let minutes = Int(recordingDuration) / 60
        let seconds = Int(recordingDuration) % 60
        return String(format: "%02d:%02d", minutes, seconds)
    }
    
    var canStartRecording: Bool {
        return permissionStatus == .granted && !isRecording && !isAnalyzing
    }
    
    var recordButtonTitle: String {
        if isAnalyzing {
            return "ë¶„ì„ ì¤‘..."
        } else if isRecording {
            return "ë…¹ìŒ ì¤‘ì§€"
        } else if permissionStatus == .granted {
            return "ë…¹ìŒ ì‹œì‘"
        } else {
            return "ê¶Œí•œ í•„ìš”"
        }
    }
    
    var statusMessage: String {
        if isAnalyzing {
            return "ì£¼íŒŒìˆ˜ ë¶„ì„ ì¤‘... \(String(format: "%.0f", analysisProgress * 100))%"
        } else if let result = analysisResult, result.isSuccessful {
            if let note = detectedNote, let freq = peakFrequency {
                return "ê°ì§€ëœ ìŒê³„: \(note) (\(String(format: "%.1f", freq))Hz)"
            } else {
                return "ë¶„ì„ ì™„ë£Œ"
            }
        } else if isRecording {
            return "ë…¹ìŒ ì¤‘... (ìµœëŒ€ 60ì´ˆ)"
        } else {
            return "ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”"
        }
    }
    
    var hasAnalysisResult: Bool {
        return analysisResult?.isSuccessful == true && !syllableSegments.isEmpty
    }
    
    var syllableNotes: [String] {
        return syllableSegments.compactMap { $0.noteName }
    }
    
    var analysisQuality: String {
        guard let result = analysisResult else { return "ë¶„ì„ ì•ˆë¨" }
        return result.qualityGrade.koreanName
    }
    
    var analysisConfidence: Double {
        return analysisResult?.overallConfidence ?? 0.0
    }
    
    // MARK: - Initialization
    
    init(
        recordAudioUseCase: RecordAudioUseCase = RecordAudioUseCase(
            audioRepository: AudioRecordingRepositoryImpl()
        ),
        syllableAnalysisUseCase: SyllableAnalysisUseCase = SyllableAnalysisUseCaseImpl(
            audioAnalysisRepository: AudioAnalysisRepositoryImpl.shared()
        ),
        synthesizeAudioUseCase: SynthesizeAudioUseCase = SynthesizeAudioUseCase(
            audioSynthesisRepository: AudioSynthesizer()
        ),
        audioPlaybackUseCase: AudioPlaybackUseCase = AudioPlaybackUseCase(
            audioPlaybackRepository: AudioPlayer()
        )
    ) {
        self.recordAudioUseCase = recordAudioUseCase
        self.syllableAnalysisUseCase = syllableAnalysisUseCase
        self.synthesizeAudioUseCase = synthesizeAudioUseCase
        self.audioPlaybackUseCase = audioPlaybackUseCase
        setupBindings()
        checkInitialPermissionStatus()
    }
    
    // MARK: - Public Methods
    
    /// ë…¹ìŒ ë²„íŠ¼ ì•¡ì…˜
    func recordButtonTapped() {
        print("ğŸ¤ ë…¹ìŒ ë²„íŠ¼ í´ë¦­ - í˜„ì¬ ìƒíƒœ: \(isRecording ? "ë…¹ìŒ ì¤‘" : "ì¤‘ì§€ë¨"), ê¶Œí•œ: \(permissionStatus)")
        
        guard permissionStatus == .granted else {
            print("âŒ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ê¶Œí•œ ì•Œë¦¼ í‘œì‹œ...")
            showingPermissionAlert = true
            return
        }
        
        if isRecording {
            print("ğŸ¤ ë…¹ìŒ ì¤‘ì§€ ì‹œë„...")
            stopRecording()
        } else {
            print("ğŸ¤ ë…¹ìŒ ì‹œì‘ ì‹œë„...")
            startRecording()
        }
    }
    
    /// ê¶Œí•œ ìš”ì²­
    func requestPermission() {
        print("ğŸ” ê¶Œí•œ ìš”ì²­ ì‹œì‘...")
        
        recordAudioUseCase.checkRecordingReadiness()
            .receive(on: DispatchQueue.main)
            .sink(
                receiveCompletion: { [weak self] completion in
                    if case .failure(let error) = completion {
                        print("âŒ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨: \(error)")
                        self?.handleError(error)
                    }
                },
                receiveValue: { [weak self] granted in
                    if granted {
                        print("âœ… ê¶Œí•œ ìŠ¹ì¸ë¨")
                        self?.permissionStatus = .granted
                    } else {
                        print("âŒ ê¶Œí•œ ê±°ë¶€ë¨")
                        self?.permissionStatus = .denied
                        self?.showingPermissionAlert = true
                    }
                }
            )
            .store(in: &cancellables)
    }
    
    /// ìŒì ˆë³„ ë¶„ì„ ì‹œì‘
    func startSyllableAnalysis() {
        guard let audioSession = currentAudioSession else {
            errorMessage = "ë¶„ì„í•  ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        }
        
        clearAnalysisResults()
        isAnalyzing = true
        analysisProgress = 0.0
        
        // ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
        startProgressSimulation()
        
        Task {
            do {
                let result = try await syllableAnalysisUseCase.analyzeSyllables(from: audioSession)
                
                await MainActor.run {
                    self.processAnalysisResult(result)
                    self.isAnalyzing = false
                    self.analysisProgress = 1.0
                }
                
            } catch {
                await MainActor.run {
                    self.handleAnalysisError(error)
                    self.isAnalyzing = false
                    self.analysisProgress = 1.0
                }
            }
        }
    }
    
    /// ê°œë³„ ìŒì ˆ ì„ íƒ
    func selectSyllable(at index: Int) {
        guard index >= 0 && index < syllableSegments.count else { return }
        selectedSyllableIndex = index
        print("ğŸ” ìŒì ˆ ì„ íƒ: \(index) - \(syllableSegments[index].noteName ?? "N/A")")
    }
    
    /// ê°œë³„ ìŒì ˆ ì¬ìƒ
    func playSyllable(at index: Int) {
        guard index >= 0 && index < syllableSegments.count else { return }
        
        let segment = syllableSegments[index]
        guard let musicNote = segment.musicNote else {
            errorMessage = "ì¬ìƒí•  ìŒê³„ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        }
        
        // ê¸°ì¡´ ì¬ìƒ ì¤‘ì§€
        stopAllPlayback()
        
        // í•©ì„± ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if synthesizedAudios[index] == nil {
            generateSynthesizedAudio(for: index, musicNote: musicNote)
        } else {
            // ë°”ë¡œ ì¬ìƒ
            playGeneratedAudio(at: index)
        }
    }
    
    /// ì „ì²´ ìŒì ˆ ìˆœì°¨ ì¬ìƒ
    func playAllSyllables() {
        guard !syllableSegments.isEmpty else {
            errorMessage = "ì¬ìƒí•  ìŒì ˆì´ ì—†ìŠµë‹ˆë‹¤."
            return
        }
        
        stopAllPlayback()
        
        // ëª¨ë“  ìŒì ˆì˜ í•©ì„± ì˜¤ë””ì˜¤ ìƒì„± ë° ìˆœì°¨ ì¬ìƒ
        generateAllSynthesizedAudios { [weak self] in
            self?.startSequentialPlayback()
        }
    }
    
    /// ì›ë³¸ ì˜¤ë””ì˜¤ ì¬ìƒ
    func playOriginalAudio() {
        guard let audioSession = currentAudioSession else {
            errorMessage = "ì¬ìƒí•  ì›ë³¸ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        }
        
        stopAllPlayback()
        
        audioPlaybackUseCase.playWithMode(
            mode: .originalOnly,
            audioSession: audioSession,
            synthesizedAudio: nil
        )
        .receive(on: DispatchQueue.main)
        .sink(
            receiveCompletion: { [weak self] completion in
                if case .failure(let error) = completion {
                    self?.handlePlaybackError(error)
                }
            },
            receiveValue: { _ in
                // ì¬ìƒ ì‹œì‘ë¨
                print("ğŸµ ì›ë³¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘")
            }
        )
        .store(in: &cancellables)
    }
    
    /// ëª¨ë“  ì¬ìƒ ì¤‘ì§€
    func stopAllPlayback() {
        audioPlaybackUseCase.stop()
        playingSyllableIndex = nil
    }
    
    /// ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
    func clearAnalysisResults() {
        analysisResult = nil
        syllableSegments = []
        selectedSyllableIndex = nil
        playingSyllableIndex = nil
        synthesizedAudios.removeAll()
        analysisProgress = 0.0
        detectedNote = nil
        peakFrequency = nil
        frequencyAccuracy = nil
    }
    
    /// ì—ëŸ¬ ë©”ì‹œì§€ ì œê±°
    func clearError() {
        errorMessage = nil
    }
    
    /// ë…¹ìŒ ì‹œì‘
    func startRecording() {
        clearError()
        clearAnalysisResults()
        
        recordAudioUseCase.startRecording()
            .receive(on: DispatchQueue.main)
            .sink(
                receiveCompletion: { [weak self] completion in
                    if case .failure(let error) = completion {
                        self?.handleError(error)
                        self?.isRecording = false
                    }
                },
                receiveValue: { [weak self] audioSession in
                    self?.currentAudioSession = audioSession
                    print("ğŸ¤ ë…¹ìŒ ì‹œì‘ë¨: \(audioSession.id)")
                }
            )
            .store(in: &cancellables)
    }
    
    /// ë…¹ìŒ ì¤‘ì§€
    func stopRecording() {
        recordAudioUseCase.stopRecording()
            .receive(on: DispatchQueue.main)
            .sink(
                receiveCompletion: { [weak self] completion in
                    if case .failure(let error) = completion {
                        self?.handleError(error)
                    }
                    self?.isRecording = false
                },
                receiveValue: { [weak self] audioSession in
                    self?.currentAudioSession = audioSession
                    self?.recordingDuration = 0
                    print("ğŸ¤ ë…¹ìŒ ì™„ë£Œ: \(audioSession.duration)ì´ˆ, íŒŒì¼: \(audioSession.audioFileURL?.lastPathComponent ?? "ì—†ìŒ")")
                    
                    // ë…¹ìŒ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ìŒì ˆë³„ ë¶„ì„ ì‹œì‘
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                        self?.startSyllableAnalysis()
                    }
                }
            )
            .store(in: &cancellables)
    }
    
    /// ë…¹ìŒ í† ê¸€ (ì‹œì‘/ì¤‘ì§€)
    func toggleRecording() {
        if isRecording {
            stopRecording()
        } else {
            startRecording()
        }
    }
    
    /// ì„¸ì…˜ ë¦¬ì…‹
    func resetSession() {
        stopAllPlayback()
        clearAnalysisResults()
        clearError()
        currentAudioSession = nil
        recordingDuration = 0
        isRecording = false
        isAnalyzing = false
        print("ğŸ”„ ì„¸ì…˜ ë¦¬ì…‹ë¨")
    }
    
    // MARK: - Private Methods
    
    private func setupBindings() {
        // ë…¹ìŒ ìƒíƒœ ê°ì§€
        Timer.publish(every: 0.1, on: .main, in: .common)
            .autoconnect()
            .sink { [weak self] _ in
                guard let self = self else { return }
                
                if self.recordAudioUseCase.isCurrentlyRecording {
                    self.isRecording = true
                    self.recordingDuration = self.recordAudioUseCase.currentDuration
                } else if self.isRecording {
                    // ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆì„ ë•Œ
                    self.isRecording = false
                }
            }
            .store(in: &cancellables)
        
        // ì¬ìƒ ìƒíƒœ ê°ì§€
        audioPlaybackUseCase.statePublisher
            .receive(on: DispatchQueue.main)
            .sink { [weak self] state in
                if state == .finished || state == .stopped {
                    self?.playingSyllableIndex = nil
                }
            }
            .store(in: &cancellables)
    }
    
    private func checkInitialPermissionStatus() {
        recordAudioUseCase.checkRecordingReadiness()
            .receive(on: DispatchQueue.main)
            .sink(
                receiveCompletion: { [weak self] completion in
                    if case .failure(let error) = completion {
                        switch error {
                        case .permissionDenied:
                            self?.permissionStatus = .denied
                        default:
                            self?.permissionStatus = .notDetermined
                        }
                    }
                },
                receiveValue: { [weak self] granted in
                    self?.permissionStatus = granted ? .granted : .denied
                }
            )
            .store(in: &cancellables)
    }
    
    private func processAnalysisResult(_ result: TimeBasedAnalysisResult) {
        analysisResult = result
        syllableSegments = result.validSpeechSegments
        
        // ContentView UIë¥¼ ìœ„í•œ ëŒ€í‘œ ìŒê³„ ì •ë³´ ì¶”ì¶œ
        extractRepresentativeNote(from: result)
        
        print("ğŸµ ìŒì ˆë³„ ë¶„ì„ ì™„ë£Œ:")
        print("   - ì´ ì„¸ê·¸ë¨¼íŠ¸: \(result.syllableSegments.count)ê°œ")
        print("   - ìœ íš¨ ìŒì ˆ: \(syllableSegments.count)ê°œ") 
        print("   - ìŒê³„ë“¤: \(syllableNotes.joined(separator: " â†’ "))")
        print("   - í’ˆì§ˆ: \(result.qualityGrade.koreanName)")
        print("   - ì‹ ë¢°ë„: \(String(format: "%.1f%%", result.overallConfidence * 100))")
        
        if let note = detectedNote, let freq = peakFrequency {
            print("   - ëŒ€í‘œ ìŒê³„: \(note) (\(String(format: "%.1f", freq))Hz)")
        }
    }
    
    /// ë¶„ì„ ê²°ê³¼ì—ì„œ ê°€ì¥ ëŒ€í‘œì ì¸ ìŒê³„ ì •ë³´ë¥¼ ì¶”ì¶œ
    private func extractRepresentativeNote(from result: TimeBasedAnalysisResult) {
        let validSegments = result.validSpeechSegments
        
        guard !validSegments.isEmpty else {
            detectedNote = nil
            peakFrequency = nil
            frequencyAccuracy = nil
            return
        }
        
        // ëª¨ë“  ìœ íš¨í•œ ì£¼íŒŒìˆ˜ë“¤ì„ ìˆ˜ì§‘
        let allFrequencies = validSegments.compactMap { $0.primaryFrequency }
        
        guard !allFrequencies.isEmpty else {
            detectedNote = nil
            peakFrequency = nil
            frequencyAccuracy = nil
            return
        }
        
        // í‰ê·  ì£¼íŒŒìˆ˜ ê³„ì‚°
        let averageFrequency = allFrequencies.reduce(0.0, +) / Double(allFrequencies.count)
        
        // ê°€ì¥ ê°€ê¹Œìš´ ìŒê³„ ì°¾ê¸°
        if let representativeNote = MusicNote.from(frequency: averageFrequency) {
            detectedNote = representativeNote.name
            peakFrequency = averageFrequency
            
            // ì •í™•ë„ ê³„ì‚° (ì‹¤ì œ ì£¼íŒŒìˆ˜ì™€ í‘œì¤€ ìŒê³„ ì£¼íŒŒìˆ˜ì˜ ì°¨ì´)
            let standardFrequency = representativeNote.frequency
            let accuracyPercentage = max(0.0, 1.0 - abs(averageFrequency - standardFrequency) / standardFrequency)
            frequencyAccuracy = accuracyPercentage
        } else {
            detectedNote = nil
            peakFrequency = averageFrequency
            frequencyAccuracy = nil
        }
    }
    
    private func generateSynthesizedAudio(for index: Int, musicNote: MusicNote) {
        isGeneratingAudio = true
        
        synthesizeAudioUseCase.synthesizeFromFrequency(
            frequency: musicNote.frequency,
            duration: 1.0,
            amplitude: 0.7,
            method: .harmonic
        )
        .receive(on: DispatchQueue.main)
        .sink(
            receiveCompletion: { [weak self] (completion: Subscribers.Completion<AudioSynthesisError>) in
                self?.isGeneratingAudio = false
                
                if case .failure(let error) = completion {
                    print("âŒ ìŒì ˆ \(index) í•©ì„± ì‹¤íŒ¨: \(error)")
                    self?.errorMessage = "ìŒì„± í•©ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            },
            receiveValue: { [weak self] (synthesizedAudio: SynthesizedAudio) in
                self?.synthesizedAudios[index] = synthesizedAudio
                self?.playGeneratedAudio(at: index)
                print("âœ… ìŒì ˆ \(index) í•©ì„± ì™„ë£Œ: \(musicNote.name)")
            }
        )
        .store(in: &cancellables)
    }
    
    private func playGeneratedAudio(at index: Int) {
        guard let synthesizedAudio = synthesizedAudios[index] else { return }
        
        playingSyllableIndex = index
        
        // ì„ì‹œ ì˜¤ë””ì˜¤ ì„¸ì…˜ ìƒì„±
        let tempSession = AudioSession(
            duration: synthesizedAudio.duration,
            sampleRate: synthesizedAudio.sampleRate
        )
        
        audioPlaybackUseCase.playWithMode(
            mode: .synthesizedOnly,
            audioSession: tempSession,
            synthesizedAudio: synthesizedAudio
        )
        .receive(on: DispatchQueue.main)
        .sink(
            receiveCompletion: { [weak self] completion in
                if case .failure(let error) = completion {
                    self?.handlePlaybackError(error)
                    self?.playingSyllableIndex = nil
                }
            },
            receiveValue: { _ in
                print("ğŸµ ìŒì ˆ \(index) ì¬ìƒ ì‹œì‘")
            }
        )
        .store(in: &cancellables)
    }
    
    private func generateAllSynthesizedAudios(completion: @escaping () -> Void) {
        let musicNotes = syllableSegments.compactMap { $0.musicNote }
        guard !musicNotes.isEmpty else {
            completion()
            return
        }
        
        isGeneratingAudio = true
        
        // ëª¨ë“  ìŒì ˆì„ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ í•©ì„±
        let frequencies = musicNotes.map { $0.frequency }
        synthesizeAudioUseCase.synthesizeSequenceFromFrequencies(
            frequencies: frequencies,
            segmentDuration: 0.8,
            amplitude: 0.7,
            method: .harmonic
        )
        .receive(on: DispatchQueue.main)
        .sink(
            receiveCompletion: { [weak self] (completionResult: Subscribers.Completion<AudioSynthesisError>) in
                self?.isGeneratingAudio = false
                
                if case .failure(let error) = completionResult {
                    print("âŒ ì „ì²´ ì‹œí€€ìŠ¤ í•©ì„± ì‹¤íŒ¨: \(error)")
                    self?.errorMessage = "ìŒì„± í•©ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            },
            receiveValue: { [weak self] (synthesizedAudio: SynthesizedAudio) in
                // ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ì¸ë±ìŠ¤ -1ì— ì €ì¥
                self?.synthesizedAudios[-1] = synthesizedAudio
                completion()
                print("âœ… ì „ì²´ ì‹œí€€ìŠ¤ í•©ì„± ì™„ë£Œ")
            }
        )
        .store(in: &cancellables)
    }
    
    private func startSequentialPlayback() {
        guard let sequenceAudio = synthesizedAudios[-1] else { return }
        
        let tempSession = AudioSession(
            duration: sequenceAudio.duration,
            sampleRate: sequenceAudio.sampleRate
        )
        
        audioPlaybackUseCase.playWithMode(
            mode: .synthesizedOnly,
            audioSession: tempSession,
            synthesizedAudio: sequenceAudio
        )
        .receive(on: DispatchQueue.main)
        .sink(
            receiveCompletion: { [weak self] completion in
                if case .failure(let error) = completion {
                    self?.handlePlaybackError(error)
                }
            },
            receiveValue: { _ in
                print("ğŸµ ì „ì²´ ì‹œí€€ìŠ¤ ì¬ìƒ ì‹œì‘")
            }
        )
        .store(in: &cancellables)
    }
    
    private func startProgressSimulation() {
        // ë¶„ì„ ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
        Timer.publish(every: 0.1, on: .main, in: .common)
            .autoconnect()
            .prefix(while: { [weak self] _ in
                self?.isAnalyzing == true && self?.analysisProgress ?? 1.0 < 0.9
            })
            .sink { [weak self] _ in
                self?.analysisProgress += 0.03
            }
            .store(in: &cancellables)
    }
    
    private func handleError(_ error: AudioRecordingError) {
        switch error {
        case .permissionDenied:
            errorMessage = "ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
            permissionStatus = .denied
            showingPermissionAlert = true
        case .recordingFailed:
            errorMessage = "ë…¹ìŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        case .recordingInProgress:
            errorMessage = "ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤."
        case .maxDurationExceeded:
            errorMessage = "ìµœëŒ€ ë…¹ìŒ ì‹œê°„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤."
        case .invalidAudioFormat:
            errorMessage = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤."
        case .fileSystemError:
            errorMessage = "íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        }
    }
    
    private func handleAnalysisError(_ error: Error) {
        if let audioError = error as? AudioAnalysisError {
            switch audioError {
            case .invalidAudioData:
                errorMessage = "ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            case .analysisTimeout:
                errorMessage = "ë¶„ì„ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
            case .insufficientData:
                errorMessage = "ë¶„ì„í•˜ê¸°ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            case .fftProcessingFailed:
                errorMessage = "ì£¼íŒŒìˆ˜ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            case .fileReadError:
                errorMessage = "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        } else {
            errorMessage = "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: \(error.localizedDescription)"
        }
    }
    
    private func handlePlaybackError(_ error: AudioPlaybackError) {
        switch error {
        case .audioFileNotFound:
            errorMessage = "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        case .unsupportedAudioFormat:
            errorMessage = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤."
        case .playbackFailed:
            errorMessage = "ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        case .seekFailed:
            errorMessage = "ì‹œê°„ ì´ë™ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        case .playerInitializationFailed:
            errorMessage = "í”Œë ˆì´ì–´ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        case .volumeAdjustmentFailed:
            errorMessage = "ë³¼ë¥¨ ì¡°ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        }
    }
}

// MARK: - Extensions

extension RecordingViewModel {
    
    /// ìŒì•… ìŠ¤ì¼€ì¼ ì¶”ì²œì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    func prepareScaleRecommendationData() -> [Int] {
        guard let result = analysisResult else { return [] }
        return result.getScaleAnalysisData()
    }
    
    /// íŠ¹ì • í’ˆì§ˆ ì´ìƒì˜ ìŒì ˆë§Œ í•„í„°ë§
    func getHighQualitySyllables() -> [SyllableSegment] {
        return syllableSegments.filter { $0.qualityGrade != .poor }
    }
    
    /// ë¶„ì„ í†µê³„ ì •ë³´
    var analysisStatistics: String {
        guard let result = analysisResult else { return "ë¶„ì„ ë°ì´í„° ì—†ìŒ" }
        
        let totalSegments = result.syllableSegments.count
        let validSegments = result.validSpeechSegments.count
        let avgConfidence = result.overallConfidence * 100
        
        return """
        ì´ ì„¸ê·¸ë¨¼íŠ¸: \(totalSegments)ê°œ
        ìœ íš¨ ìŒì ˆ: \(validSegments)ê°œ
        í‰ê·  ì‹ ë¢°ë„: \(String(format: "%.1f", avgConfidence))%
        ë¶„ì„ í’ˆì§ˆ: \(result.qualityGrade.koreanName)
        """
    }
    
    /// ì„ íƒëœ ìŠ¤ì¼€ì¼ ì„¤ì •
    func setSelectedScale(_ scale: MusicScale) {
        // ì„ íƒëœ ìŠ¤ì¼€ì¼ì„ í˜„ì¬ ì„¸ì…˜ì— ì—°ê²°
        print("ğŸ¼ ìŠ¤ì¼€ì¼ ì„ íƒë¨: \(scale.name)")
        
        // ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°± ì œê³µ
        if scale.notes.count > 0 {
            let noteNames = scale.notes.prefix(3).map { $0.name }.joined(separator: ", ")
            infoMessage = "\(scale.name) ìŠ¤ì¼€ì¼ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤ (\(noteNames)...)"
            
            // 3ì´ˆ í›„ ë©”ì‹œì§€ ìë™ ì œê±°
            DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
                self.infoMessage = nil
            }
        }
    }
    
    /// ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
    func setErrorMessage(_ message: String) {
        errorMessage = message
        
        // 5ì´ˆ í›„ ìë™ìœ¼ë¡œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê±°
        DispatchQueue.main.asyncAfter(deadline: .now() + 5.0) {
            if self.errorMessage == message {
                self.errorMessage = nil
            }
        }
    }
    
    /// ì •ë³´ ë©”ì‹œì§€ ì„¤ì •
    func setInfoMessage(_ message: String) {
        infoMessage = message
        
        // 3ì´ˆ í›„ ìë™ìœ¼ë¡œ ì •ë³´ ë©”ì‹œì§€ ì œê±°
        DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
            if self.infoMessage == message {
                self.infoMessage = nil
            }
        }
    }
    
    /// ì—ëŸ¬ ë©”ì‹œì§€ ì œê±°
    func clearErrorMessage() {
        errorMessage = nil
    }
    
    /// ì •ë³´ ë©”ì‹œì§€ ì œê±°
    func clearInfoMessage() {
        infoMessage = nil
    }
} 