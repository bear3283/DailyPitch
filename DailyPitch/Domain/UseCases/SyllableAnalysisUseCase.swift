import Foundation
import AVFoundation

/// ì˜¤ë””ì˜¤ë¥¼ ìŒì ˆë³„ë¡œ ë¶„ì„í•˜ì—¬ ê°œë³„ ìŒê³„ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ìŠ¤ì¼€ì´ìŠ¤
/// "ì•ˆë…•í•˜ì„¸ìš”" â†’ ["ì•ˆ": F4, "ë…•": G4, "í•˜": A4, "ì„¸": B4, "ìš”": C5] í˜•íƒœë¡œ ë¶„ì„
protocol SyllableAnalysisUseCase {
    /// ì˜¤ë””ì˜¤ ì„¸ì…˜ì„ ìŒì ˆë³„ë¡œ ë¶„ì„
    /// - Parameter audioSession: ë¶„ì„í•  ì˜¤ë””ì˜¤ ì„¸ì…˜
    /// - Returns: ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
    func analyzeSyllables(from audioSession: AudioSession) async throws -> TimeBasedAnalysisResult
    
    /// ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ìŒì ˆë³„ë¡œ ë¶„ì„
    /// - Parameter buffer: ì˜¤ë””ì˜¤ ë²„í¼
    /// - Returns: ê°œë³„ ìŒì ˆ ì„¸ê·¸ë¨¼íŠ¸ (ì˜µì…”ë„)
    func analyzeRealtimeBuffer(_ buffer: AVAudioPCMBuffer) async -> SyllableSegment?
    
    /// ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìŒì ˆë³„ë¡œ ë¶„ì„
    /// - Parameter fileURL: ì˜¤ë””ì˜¤ íŒŒì¼ URL
    /// - Returns: ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
    func analyzeSyllables(from fileURL: URL) async throws -> TimeBasedAnalysisResult
}

/// SyllableAnalysisUseCaseì˜ êµ¬í˜„ì²´
class SyllableAnalysisUseCaseImpl: SyllableAnalysisUseCase {
    
    // MARK: - Dependencies
    
    private let audioAnalysisRepository: AudioAnalysisRepository
    private let fftAnalyzer: FFTAnalyzer
    private let voiceActivityDetector: VoiceActivityDetector
    private let syllableSegmentationEngine: SyllableSegmentationEngine
    
    // MARK: - Configuration
    
    /// FFT ì„¤ì •
    private let fftSize: Int
    private let overlapRatio: Double
    
    /// ìŒì„± í™œë™ ê°ì§€ ì„¤ì •
    private let minSpeechDuration: TimeInterval
    private let minSilenceBetweenSyllables: TimeInterval
    
    // MARK: - Initialization
    
    init(
        audioAnalysisRepository: AudioAnalysisRepository,
        fftSize: Int = 1024,
        overlapRatio: Double = 0.75,  // 75% ê²¹ì¹¨ìœ¼ë¡œ ë” ì„¸ë°€í•œ ë¶„ì„
        minSpeechDuration: TimeInterval = 0.2,  // ìµœì†Œ 200ms ìŒì„± (ë” ì—„ê²©)
        minSilenceBetweenSyllables: TimeInterval = 0.1,  // ìŒì ˆ ê°„ ìµœì†Œ 100ms ë¬´ìŒ (ë” ì—„ê²©)
        vadConfiguration: VoiceActivityDetector.VADConfiguration = .significantChangeOnly  // ì˜ë¯¸ìˆëŠ” ë³€í™”ë§Œ ê°ì§€
    ) {
        self.audioAnalysisRepository = audioAnalysisRepository
        self.fftSize = fftSize
        self.overlapRatio = overlapRatio
        self.minSpeechDuration = minSpeechDuration
        self.minSilenceBetweenSyllables = minSilenceBetweenSyllables
        
        // FFT ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.fftAnalyzer = FFTAnalyzer(fftSize: fftSize, overlapRatio: overlapRatio)
        
        // VAD ì´ˆê¸°í™” - ì˜ë¯¸ìˆëŠ” ë³€í™”ë§Œ ê°ì§€í•˜ëŠ” ì—„ê²©í•œ ì„¤ì • ì‚¬ìš©
        self.voiceActivityDetector = VoiceActivityDetector(
            configuration: vadConfiguration,
            frameSize: fftSize
        )
        
        // ìŒì ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—”ì§„ ì´ˆê¸°í™” - ì˜ë¯¸ìˆëŠ” ë³€í™”ë§Œ ê°ì§€í•˜ëŠ” ì„¤ì • ì‚¬ìš©
        self.syllableSegmentationEngine = SyllableSegmentationEngine(
            configuration: .significantChangeOnly,  // ì—„ê²©í•œ ìŒì ˆ ë¶„ë¦¬ ì„¤ì •
            frameSize: fftSize
        )
    }
    
    // MARK: - Public Methods
    
    func analyzeSyllables(from audioSession: AudioSession) async throws -> TimeBasedAnalysisResult {
        guard let audioFileURL = audioSession.audioFileURL else {
            throw AudioAnalysisError.fileReadError
        }
        
        return try await analyzeSyllables(from: audioFileURL)
    }
    
    func analyzeRealtimeBuffer(_ buffer: AVAudioPCMBuffer) async -> SyllableSegment? {
        // ì‹¤ì‹œê°„ ë²„í¼ ë¶„ì„
        guard let frequencyData = fftAnalyzer.analyzeBuffer(buffer, sampleRate: buffer.format.sampleRate) else {
            return nil
        }
        
        // ìœˆë„ìš° ì§€ì†ì‹œê°„ ê³„ì‚°
        let windowDuration = Double(buffer.frameLength) / buffer.format.sampleRate
        
        // SyllableSegment ìƒì„±
        let segment = SyllableSegment.from(
            frequencyData: frequencyData,
            index: 0, // ì‹¤ì‹œê°„ì—ì„œëŠ” ì¸ë±ìŠ¤ 0
            windowDuration: windowDuration
        )
        
        // ìœ íš¨í•œ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ì¸ì§€ í™•ì¸
        return segment.isValid ? segment : nil
    }
    
    func analyzeSyllables(from fileURL: URL) async throws -> TimeBasedAnalysisResult {
        return try await withCheckedThrowingContinuation { continuation in
            print("ğŸµ VAD ê¸°ë°˜ ìŒì ˆë³„ ë¶„ì„ ì‹œì‘: \(fileURL.lastPathComponent)")
            
            // VAD ì´ˆê¸°í™”
            self.voiceActivityDetector.reset()
            
            do {
                // 1ë‹¨ê³„: ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
                let audioFile = try AVAudioFile(forReading: fileURL)
                let format = audioFile.processingFormat
                let frameCount = AVAudioFrameCount(audioFile.length)
                
                guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
                    continuation.resume(throwing: AudioAnalysisError.invalidAudioData)
                    return
                }
                
                try audioFile.read(into: buffer)
                
                guard let channelData = buffer.floatChannelData else {
                    continuation.resume(throwing: AudioAnalysisError.invalidAudioData)
                    return
                }
                
                let audioData = Array(UnsafeBufferPointer(start: channelData[0], count: Int(frameCount)))
                
                print("ğŸ” VAD ë¶„ì„ ì‹œì‘ - ì´ ìƒ˜í”Œ: \(audioData.count), ê¸¸ì´: \(String(format: "%.2f", Double(audioData.count) / format.sampleRate))ì´ˆ")
                
                // 2ë‹¨ê³„: VADë¥¼ í†µí•œ ìŒì„± í™œë™ ê²€ì¶œ
                let vadResults = self.voiceActivityDetector.detectVoiceActivity(in: audioData)
                let vadSegments = self.voiceActivityDetector.createSegments(from: vadResults)
                let speechOnlySegments = self.voiceActivityDetector.speechSegments(from: vadSegments)
                
                print("ğŸ” VAD ê²°ê³¼: \(vadSegments.count)ê°œ ì „ì²´ êµ¬ê°„, \(speechOnlySegments.count)ê°œ ìŒì„± êµ¬ê°„")
                
                // 3ë‹¨ê³„: ê³ ê¸‰ ìŒì ˆ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì ìš©
                let segmentationResults = self.syllableSegmentationEngine.segmentMultipleSpeechSegments(
                    vadSegments: speechOnlySegments,
                    audioData: audioData
                )
                
                // 4ë‹¨ê³„: ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ FFT ë¶„ì„ ë° SyllableSegment ìƒì„±
                var syllableSegments: [SyllableSegment] = []
                
                for (segmentIndex, segmentationResult) in segmentationResults.enumerated() {
                    let boundaries = segmentationResult.syllableBoundaries
                    
                    print("ğŸ”ª êµ¬ê°„ \(segmentIndex + 1): \(boundaries.count-1)ê°œ ìŒì ˆ ê²€ì¶œ")
                    
                    // ê° ìŒì ˆë³„ë¡œ FFT ë¶„ì„ ìˆ˜í–‰
                    for i in 0..<boundaries.count - 1 {
                        let syllableStart = boundaries[i]
                        let syllableEnd = boundaries[i + 1]
                        
                        let startSample = Int(syllableStart * format.sampleRate)
                        let endSample = Int(syllableEnd * format.sampleRate)
                        
                        guard startSample >= 0 && endSample <= audioData.count && startSample < endSample else {
                            print("âš ï¸ ìŒì ˆ ë²”ìœ„ ì˜¤ë¥˜: \(startSample)~\(endSample)")
                            continue
                        }
                        
                        let syllableAudioData = Array(audioData[startSample..<endSample])
                        
                        // ìŒì ˆë³„ FFT ë¶„ì„
                        let frequencyDataArray = self.fftAnalyzer.analyzeTimeSegments(
                            audioData: syllableAudioData,
                            sampleRate: format.sampleRate
                        )
                        
                        // ëŒ€í‘œ ì£¼íŒŒìˆ˜ ë°ì´í„° ì„ íƒ (ê°€ì¥ ê°•í•œ ì‹ í˜¸)
                        let dominantFrequencyData = frequencyDataArray.max { first, second in
                            let firstPeak = first.peakMagnitude ?? 0.0
                            let secondPeak = second.peakMagnitude ?? 0.0
                            return firstPeak < secondPeak
                        }
                        
                        if let frequencyData = dominantFrequencyData {
                            let musicNote = frequencyData.peakFrequency.flatMap { MusicNote.from(frequency: $0) }
                            let syllableSegment = SyllableSegment(
                                index: syllableSegments.count,
                                startTime: syllableStart,
                                endTime: syllableEnd,
                                frequencyData: frequencyData,
                                musicNote: musicNote,
                                energy: segmentationResult.energyProfile.reduce(0, +) / Double(max(1, segmentationResult.energyProfile.count)),
                                confidence: segmentationResult.confidence,
                                type: .speech
                            )
                            
                            syllableSegments.append(syllableSegment)
                            
                            let noteString = syllableSegment.musicNote?.description ?? "Unknown"
                            print("ğŸµ ìŒì ˆ \(syllableSegments.count): \(String(format: "%.3f", syllableStart))~\(String(format: "%.3f", syllableEnd))ì´ˆ â†’ \(noteString)")
                        }
                    }
                }
                
                // 5ë‹¨ê³„: ìµœì¢… ì •ì œ ë° í’ˆì§ˆ í•„í„°ë§ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—”ì§„ ê¸°ë°˜)
                let refinedSegments = self.applyAdvancedQualityFiltering(syllableSegments)
                
                // 6ë‹¨ê³„: ì˜¤ë””ì˜¤ ì„¸ì…˜ ë° ê²°ê³¼ ìƒì„±
                let audioSession = AudioSession(
                    duration: Double(frameCount) / format.sampleRate,
                    audioFileURL: fileURL,
                    sampleRate: format.sampleRate,
                    channelCount: Int(format.channelCount)
                )
                
                let analysisResult = self.createAnalysisResult(
                    from: refinedSegments,
                    audioSession: audioSession
                )
                
                print("ğŸµ VAD ê¸°ë°˜ ìŒì ˆë³„ ë¶„ì„ ì™„ë£Œ: \(analysisResult.syllableNotes.joined(separator: " â†’ "))")
                print("ğŸµ ë¶„ì„ í’ˆì§ˆ: \(analysisResult.qualityGrade.koreanName) (ì‹ ë¢°ë„: \(String(format: "%.1f%%", analysisResult.overallConfidence * 100)))")
                
                continuation.resume(returning: analysisResult)
                
            } catch {
                print("âŒ VAD ê¸°ë°˜ ìŒì ˆë³„ ë¶„ì„ ì‹¤íŒ¨: \(error)")
                continuation.resume(throwing: error)
            }
        }
    }
    
    // MARK: - Private Methods (VAD ê¸°ë°˜)
    
    // MARK: - Deprecated Methods (Replaced by SyllableSegmentationEngine)
    
    @available(*, deprecated, message: "Use SyllableSegmentationEngine instead")
    private func convertToSyllableSegments(
        frequencyDataArray: [FrequencyData],
        vadSegment: VoiceActivityDetector.VADSegment,
        baseIndex: Int
    ) -> [SyllableSegment] {
        // Legacy implementation preserved for compatibility
        return []
    }
    
    /// ê³ ê¸‰ í’ˆì§ˆ í•„í„°ë§ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—”ì§„ ê²°ê³¼ ê¸°ë°˜)
    /// - Parameter segments: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—”ì§„ìœ¼ë¡œ ìƒì„±ëœ ìŒì ˆ ì„¸ê·¸ë¨¼íŠ¸ë“¤
    /// - Returns: ê³ í’ˆì§ˆ ì„¸ê·¸ë¨¼íŠ¸ë“¤
    private func applyAdvancedQualityFiltering(_ segments: [SyllableSegment]) -> [SyllableSegment] {
        // 1ë‹¨ê³„: ê¸°ë³¸ í’ˆì§ˆ í•„í„°ë§ (ë” ì—„ê²©í•œ ê¸°ì¤€)
        let basicFiltered = segments.filter { segment in
            segment.confidence > 0.6 &&          // ì‹ ë¢°ë„ 60% ì´ìƒ (ê¸°ì¡´ 40%ì—ì„œ ìƒí–¥)
            segment.energy > 0.08 &&             // ì—ë„ˆì§€ 8% ì´ìƒ (ê¸°ì¡´ 3%ì—ì„œ ëŒ€í­ ìƒí–¥)
            segment.duration >= 0.2 &&           // ìµœì†Œ 0.2ì´ˆ ì§€ì† (ê¸°ì¡´ 0.08ì´ˆì—ì„œ ìƒí–¥)
            segment.duration <= 1.0 &&           // ìµœëŒ€ 1ì´ˆ
            segment.musicNote != nil
        }
        
        // 2ë‹¨ê³„: ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ í•„í„°ë§ (ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì˜ë¯¸ìˆëŠ” ë³€í™”ë§Œ ìœ ì§€)
        let energyChangeFiltered = applyEnergyChangeFiltering(basicFiltered)
        
        // 3ë‹¨ê³„: ì£¼íŒŒìˆ˜ ë³€í™” ê¸°ë°˜ í•„í„°ë§ (ê¸‰ê²©í•œ ìŒê³„ ë³€í™”ë§Œ ìœ ì§€)
        let frequencyChangeFiltered = applyFrequencyChangeFiltering(energyChangeFiltered)
        
        // 4ë‹¨ê³„: ë°±ê·¸ë¼ìš´ë“œ ë…¸ì´ì¦ˆ ì œê±° (ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ ì‹ í˜¸ ì œê±°)
        let noiseFiltered = removeBackgroundNoise(frequencyChangeFiltered)
        
        // ì¸ë±ìŠ¤ ì¬ì •ë ¬
        let reindexedSegments = noiseFiltered.enumerated().map { index, segment in
            SyllableSegment(
                index: index,
                startTime: segment.startTime,
                endTime: segment.endTime,
                frequencyData: segment.frequencyData,
                musicNote: segment.musicNote,
                energy: segment.energy,
                confidence: segment.confidence,
                type: segment.type
            )
        }
        
        print("ğŸ” ê³ ê¸‰ í’ˆì§ˆ í•„í„°ë§:")
        print("   - ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—”ì§„ ê²°ê³¼: \(segments.count)ê°œ")
        print("   - ê¸°ë³¸ í’ˆì§ˆ í•„í„°ë§ í›„: \(basicFiltered.count)ê°œ")
        print("   - ì—ë„ˆì§€ ë³€í™” í•„í„°ë§ í›„: \(energyChangeFiltered.count)ê°œ")
        print("   - ì£¼íŒŒìˆ˜ ë³€í™” í•„í„°ë§ í›„: \(frequencyChangeFiltered.count)ê°œ")
        print("   - ë…¸ì´ì¦ˆ ì œê±° í›„: \(noiseFiltered.count)ê°œ")
        print("   - ìµœì¢… ìŒì ˆ: \(reindexedSegments.count)ê°œ")
        
        return reindexedSegments
    }
    
    /// ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ í•„í„°ë§ (ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì˜ë¯¸ìˆëŠ” ë³€í™”ë§Œ ìœ ì§€)
    private func applyEnergyChangeFiltering(_ segments: [SyllableSegment]) -> [SyllableSegment] {
        guard segments.count > 1 else { return segments }
        
        var filtered: [SyllableSegment] = []
        let energyChangeThreshold = 0.5  // 50% ì´ìƒ ì—ë„ˆì§€ ë³€í™”ë§Œ ìœ ì§€
        
        // ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ëŠ” í•­ìƒ í¬í•¨
        if let first = segments.first {
            filtered.append(first)
        }
        
        for i in 1..<segments.count {
            let current = segments[i]
            let previous = segments[i-1]
            
            let energyChange = abs(current.energy - previous.energy) / max(previous.energy, 0.01)
            
            // ì—ë„ˆì§€ ë³€í™”ê°€ ì„ê³„ê°’ ì´ìƒì´ê±°ë‚˜, ìŒê³„ê°€ í¬ê²Œ ë³€í•œ ê²½ìš° í¬í•¨
            if energyChange >= energyChangeThreshold || hasSignificantPitchChange(previous, current) {
                filtered.append(current)
            }
        }
        
        return filtered
    }
    
    /// ì£¼íŒŒìˆ˜ ë³€í™” ê¸°ë°˜ í•„í„°ë§ (ê¸‰ê²©í•œ ìŒê³„ ë³€í™”ë§Œ ìœ ì§€)
    private func applyFrequencyChangeFiltering(_ segments: [SyllableSegment]) -> [SyllableSegment] {
        guard segments.count > 1 else { return segments }
        
        var filtered: [SyllableSegment] = []
        let frequencyChangeThreshold = 100.0  // 100Hz ì´ìƒ ë³€í™”ë§Œ ìœ ì§€
        
        // ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ëŠ” í•­ìƒ í¬í•¨
        if let first = segments.first {
            filtered.append(first)
        }
        
        for i in 1..<segments.count {
            let current = segments[i]
            let previous = segments[i-1]
            
            guard let currentFreq = current.musicNote?.frequency,
                  let previousFreq = previous.musicNote?.frequency else {
                // ì£¼íŒŒìˆ˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ í¬í•¨
                filtered.append(current)
                continue
            }
            
            let frequencyChange = abs(currentFreq - previousFreq)
            
            // ì£¼íŒŒìˆ˜ ë³€í™”ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨
            if frequencyChange >= frequencyChangeThreshold {
                filtered.append(current)
            }
        }
        
        return filtered
    }
    
    /// ë°±ê·¸ë¼ìš´ë“œ ë…¸ì´ì¦ˆ ì œê±° (ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ ì‹ í˜¸ ì œê±°)
    private func removeBackgroundNoise(_ segments: [SyllableSegment]) -> [SyllableSegment] {
        guard !segments.isEmpty else { return segments }
        
        // ì „ì²´ ì—ë„ˆì§€ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        let energies = segments.map { $0.energy }
        let meanEnergy = energies.reduce(0, +) / Double(energies.count)
        let variance = energies.map { pow($0 - meanEnergy, 2) }.reduce(0, +) / Double(energies.count)
        let stdDeviation = sqrt(variance)
        
        // í‰ê·  + í‘œì¤€í¸ì°¨ ì´ìƒì˜ ì—ë„ˆì§€ë¥¼ ê°€ì§„ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ìœ ì§€
        let energyThreshold = meanEnergy + stdDeviation
        
        let filtered = segments.filter { segment in
            segment.energy >= energyThreshold
        }
        
        print("ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±°: í‰ê·  ì—ë„ˆì§€ \(String(format: "%.3f", meanEnergy)), ì„ê³„ê°’ \(String(format: "%.3f", energyThreshold))")
        
        return filtered
    }
    
    /// ë‘ ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì˜ë¯¸ìˆëŠ” ìŒê³„ ë³€í™”ê°€ ìˆëŠ”ì§€ í™•ì¸
    private func hasSignificantPitchChange(_ previous: SyllableSegment, _ current: SyllableSegment) -> Bool {
        guard let prevNote = previous.musicNote, let currNote = current.musicNote else {
            return false
        }
        
        // 3ë°˜ìŒ(minor third) ì´ìƒ ë³€í™”ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ìˆëŠ” ë³€í™”ë¡œ ê°„ì£¼
        let semitoneDifference = abs(currNote.midiNumber - prevNote.midiNumber)
        return semitoneDifference >= 3
    }
    
    // MARK: - Legacy Methods (Deprecated)
    
    /// í’ˆì§ˆ ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ í•„í„°ë§
    /// - Parameter segments: í•„í„°ë§í•  ì„¸ê·¸ë¨¼íŠ¸ë“¤
    /// - Returns: í’ˆì§ˆ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ë“¤
    private func filterByQuality(_ segments: [SyllableSegment]) -> [SyllableSegment] {
        // ìµœì†Œ í’ˆì§ˆ ê¸°ì¤€: Fair ì´ìƒ
        return segments.filter { segment in
            segment.qualityGrade != .poor &&
            segment.confidence > 0.2 &&
            segment.energy > 0.03
        }
    }
    
    /// ì˜¤ë””ì˜¤ íŒŒì¼ URLë¡œë¶€í„° AudioSession ìƒì„±
    /// - Parameters:
    ///   - fileURL: ì˜¤ë””ì˜¤ íŒŒì¼ URL
    ///   - frequencyDataArray: ì£¼íŒŒìˆ˜ ë°ì´í„° ë°°ì—´
    /// - Returns: ìƒì„±ëœ ì˜¤ë””ì˜¤ ì„¸ì…˜
    private func createAudioSession(from fileURL: URL, frequencyDataArray: [FrequencyData]) -> AudioSession {
        let sampleRate = frequencyDataArray.first?.sampleRate ?? 44100.0
        let totalFrames = frequencyDataArray.count * fftSize
        let duration = Double(totalFrames) / sampleRate
        
        return AudioSession(
            duration: duration,
            audioFileURL: fileURL,
            sampleRate: sampleRate,
            channelCount: 1
        )
    }
    
    /// ì •ì œëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ë¡œë¶€í„° ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±
    /// - Parameters:
    ///   - syllableSegments: ì •ì œëœ ìŒì ˆ ì„¸ê·¸ë¨¼íŠ¸ë“¤
    ///   - audioSession: ì˜¤ë””ì˜¤ ì„¸ì…˜ ì •ë³´
    /// - Returns: ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
    private func createAnalysisResult(
        from syllableSegments: [SyllableSegment],
        audioSession: AudioSession
    ) -> TimeBasedAnalysisResult {
        // ë¶„ì„ ë©”íƒ€ë°ì´í„° ìƒì„±
        let metadata = AnalysisMetadata(
            totalSegments: syllableSegments.count,
            validSegments: syllableSegments.speechSegments.count,
            averageEnergy: syllableSegments.speechSegments.isEmpty ? 0.0 :
                syllableSegments.speechSegments.reduce(0) { $0 + $1.energy } / Double(syllableSegments.speechSegments.count),
            frequencyRange: syllableSegments.frequencyRange,
            analysisMethod: .timeDomain,
            windowSize: Double(fftSize) / audioSession.sampleRate
        )
        
        return TimeBasedAnalysisResult(
            audioSession: audioSession,
            syllableSegments: syllableSegments,
            status: .completed,
            analysisStartTime: Date().addingTimeInterval(-1), // 1ì´ˆ ì „ì— ì‹œì‘í–ˆë‹¤ê³  ê°€ì •
            analysisEndTime: Date(),
            error: nil,
            metadata: metadata
        )
    }
}

// MARK: - Extensions

extension SyllableAnalysisUseCaseImpl {
    
    /// ë¶„ì„ ê²°ê³¼ë¥¼ ìŒì•… ìŠ¤ì¼€ì¼ ì¶”ì²œì„ ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜
    /// - Parameter analysisResult: ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼
    /// - Returns: ìŠ¤ì¼€ì¼ ë¶„ì„ì„ ìœ„í•œ ìŒì • ë°ì´í„°
    func prepareForScaleRecommendation(_ analysisResult: TimeBasedAnalysisResult) -> [Int] {
        return analysisResult.getScaleAnalysisData()
    }
    
    /// ë¶„ì„ ì„¤ì • ì—…ë°ì´íŠ¸
    /// - Parameters:
    ///   - sensitivity: ê°ë„ (0.0 ~ 1.0)
    ///   - minDuration: ìµœì†Œ ìŒì„± ì§€ì†ì‹œê°„
    func updateAnalysisSettings(sensitivity: Double, minDuration: TimeInterval) {
        // ëŸ°íƒ€ì„ì—ì„œ ì„¤ì • ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°ë¥¼ ìœ„í•œ í™•ì¥ í¬ì¸íŠ¸
        print("ğŸ”§ ë¶„ì„ ì„¤ì • ì—…ë°ì´íŠ¸: ê°ë„=\(sensitivity), ìµœì†Œì§€ì†ì‹œê°„=\(minDuration)s")
    }
} 